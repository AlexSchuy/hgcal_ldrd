Model: 
PointNet(
  (sa1_module): SAModule(
    (conv): PointConv(local_nn=Sequential(
      (0): Sequential(
        (0): Linear(in_features=6, out_features=64, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Sequential(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    ), global_nn=None)
  )
  (sa2_module): SAModule(
    (conv): PointConv(local_nn=Sequential(
      (0): Sequential(
        (0): Linear(in_features=131, out_features=128, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    ), global_nn=None)
  )
  (sa3_module): SAModule(
    (conv): PointConv(local_nn=Sequential(
      (0): Sequential(
        (0): Linear(in_features=259, out_features=256, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    ), global_nn=None)
  )
  (sa4_module): GlobalSAModule(
    (nn): Sequential(
      (0): Sequential(
        (0): Linear(in_features=259, out_features=256, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=512, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Sequential(
        (0): Linear(in_features=512, out_features=1024, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (fp3_module): FPModule(
    (nn): Sequential(
      (0): Sequential(
        (0): Linear(in_features=1280, out_features=256, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (fp2_module): FPModule(
    (nn): Sequential(
      (0): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (fp1_module): FPModule(
    (nn): Sequential(
      (0): Sequential(
        (0): Linear(in_features=384, out_features=256, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (fp0_module): FPModule(
    (nn): Sequential(
      (0): Sequential(
        (0): Linear(in_features=131, out_features=128, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Sequential(
        (0): Linear(in_features=128, out_features=64, bias=True)
        (1): ReLU()
        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (lin2): Linear(in_features=64, out_features=64, bias=True)
  (lin3): Linear(in_features=64, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
Parameters: 1766657
Training with 3600 samples
Validating with 200 samples
scor 1689882 stru 216973.0 sfls 3875453 stp 215458 stn 1474423 sfp 2401029 sfn 1515 stot 4092426
Epoch: 00, Training Loss: 0.000044713374966
               Validation Loss: 0.000010602698239, Eff.: 0.9930, FalsePos: 0.6195, FalseNeg: 0.0070, Purity: 0.0823
New best model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9930.purity0.0823.20190809.150916.0.best.pth
scor 3341700 stru 216973.0 sfls 3875453 stp 210288 stn 3131411 sfp 744041 sfn 6685 stot 4092426
Epoch: 01, Training Loss: 0.000032252094572
               Validation Loss: 0.000011519604413, Eff.: 0.9692, FalsePos: 0.1920, FalseNeg: 0.0308, Purity: 0.2204
scor 3190947 stru 216973.0 sfls 3875453 stp 211422 stn 2979525 sfp 895928 sfn 5551 stot 4092426
Epoch: 02, Training Loss: 0.000025062766324
               Validation Loss: 0.000008867496035, Eff.: 0.9744, FalsePos: 0.2312, FalseNeg: 0.0256, Purity: 0.1909
New best model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9744.purity0.1909.20190809.150916.2.best.pth
scor 2442491 stru 216973.0 sfls 3875453 stp 213125 stn 2229366 sfp 1646087 sfn 3848 stot 4092426
Epoch: 03, Training Loss: 0.000018836097750
               Validation Loss: 0.000008226769751, Eff.: 0.9823, FalsePos: 0.4247, FalseNeg: 0.0177, Purity: 0.1146
New best model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9823.purity0.1146.20190809.150916.3.best.pth
scor 2262665 stru 216973.0 sfls 3875453 stp 214486 stn 2048178 sfp 1827274 sfn 2487 stot 4092426
Epoch: 04, Training Loss: 0.000013525994810
               Validation Loss: 0.000009710204722, Eff.: 0.9885, FalsePos: 0.4715, FalseNeg: 0.0115, Purity: 0.1050
scor 1966858 stru 216973.0 sfls 3875453 stp 215459 stn 1751398 sfp 2124054 sfn 1514 stot 4092426
Epoch: 05, Training Loss: 0.000010394183741
               Validation Loss: 0.000008089060429, Eff.: 0.9930, FalsePos: 0.5481, FalseNeg: 0.0070, Purity: 0.0921
New best model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9930.purity0.0921.20190809.150916.5.best.pth
scor 2166231 stru 216973.0 sfls 3875453 stp 215420 stn 1950811 sfp 1924642 sfn 1553 stot 4092426
Epoch: 06, Training Loss: 0.000008722296253
               Validation Loss: 0.000007966241355, Eff.: 0.9928, FalsePos: 0.4966, FalseNeg: 0.0072, Purity: 0.1007
New best model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9928.purity0.1007.20190809.150916.6.best.pth
scor 1934514 stru 216973.0 sfls 3875453 stp 213457 stn 1721057 sfp 2154396 sfn 3516 stot 4092426
Epoch: 07, Training Loss: 0.000009024499746
               Validation Loss: 0.000009536918697, Eff.: 0.9838, FalsePos: 0.5559, FalseNeg: 0.0162, Purity: 0.0901
scor 2109906 stru 216973.0 sfls 3875453 stp 215141 stn 1894763 sfp 1980688 sfn 1832 stot 4092426
Epoch: 08, Training Loss: 0.000008055918054
               Validation Loss: 0.000007672012543, Eff.: 0.9916, FalsePos: 0.5111, FalseNeg: 0.0084, Purity: 0.0980
New best model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9916.purity0.0980.20190809.150916.8.best.pth
scor 2315442 stru 216973.0 sfls 3875453 stp 215237 stn 2100205 sfp 1775248 sfn 1736 stot 4092426
Epoch: 09, Training Loss: 0.000007812034399
               Validation Loss: 0.000007754902981, Eff.: 0.9920, FalsePos: 0.4581, FalseNeg: 0.0080, Purity: 0.1081
scor 2397417 stru 216973.0 sfls 3875453 stp 214714 stn 2182703 sfp 1692750 sfn 2259 stot 4092426
Epoch: 10, Training Loss: 0.000008738245114
               Validation Loss: 0.000008057409104, Eff.: 0.9896, FalsePos: 0.4368, FalseNeg: 0.0104, Purity: 0.1126
scor 2571040 stru 216973.0 sfls 3875453 stp 213848 stn 2357192 sfp 1518261 sfn 3125 stot 4092426
Epoch: 11, Training Loss: 0.000010771689478
               Validation Loss: 0.000010061398825, Eff.: 0.9856, FalsePos: 0.3918, FalseNeg: 0.0144, Purity: 0.1235
scor 2623743 stru 216973.0 sfls 3875453 stp 215120 stn 2408623 sfp 1466830 sfn 1853 stot 4092426
Epoch: 12, Training Loss: 0.000008409158189
               Validation Loss: 0.000007515825928, Eff.: 0.9915, FalsePos: 0.3785, FalseNeg: 0.0085, Purity: 0.1279
New best model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9915.purity0.1279.20190809.150916.12.best.pth
scor 2820810 stru 216973.0 sfls 3875453 stp 215464 stn 2605346 sfp 1270107 sfn 1509 stot 4092426
Epoch: 13, Training Loss: 0.000006274821100
               Validation Loss: 0.000005778994364, Eff.: 0.9930, FalsePos: 0.3277, FalseNeg: 0.0070, Purity: 0.1450
New best model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9930.purity0.1450.20190809.150916.13.best.pth
scor 2977457 stru 216973.0 sfls 3875453 stp 215356 stn 2762101 sfp 1113352 sfn 1617 stot 4092426
Epoch: 14, Training Loss: 0.000005398955739
               Validation Loss: 0.000005638969924, Eff.: 0.9925, FalsePos: 0.2873, FalseNeg: 0.0075, Purity: 0.1621
New best model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9925.purity0.1621.20190809.150916.14.best.pth
scor 3112958 stru 216973.0 sfls 3875453 stp 215373 stn 2897585 sfp 977868 sfn 1600 stot 4092426
Epoch: 15, Training Loss: 0.000004858629625
               Validation Loss: 0.000004600363354, Eff.: 0.9926, FalsePos: 0.2523, FalseNeg: 0.0074, Purity: 0.1805
New best model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9926.purity0.1805.20190809.150916.15.best.pth
scor 3123267 stru 216973.0 sfls 3875453 stp 215160 stn 2908107 sfp 967346 sfn 1813 stot 4092426
Epoch: 16, Training Loss: 0.000004541322439
               Validation Loss: 0.000004929824172, Eff.: 0.9916, FalsePos: 0.2496, FalseNeg: 0.0084, Purity: 0.1820
scor 3332078 stru 216973.0 sfls 3875453 stp 215014 stn 3117064 sfp 758389 sfn 1959 stot 4092426
Epoch: 17, Training Loss: 0.000004276211043
               Validation Loss: 0.000004325624104, Eff.: 0.9910, FalsePos: 0.1957, FalseNeg: 0.0090, Purity: 0.2209
New best model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9910.purity0.2209.20190809.150916.17.best.pth
scor 3351977 stru 216973.0 sfls 3875453 stp 215204 stn 3136773 sfp 738680 sfn 1769 stot 4092426
Epoch: 18, Training Loss: 0.000004052636613
               Validation Loss: 0.000004094240467, Eff.: 0.9918, FalsePos: 0.1906, FalseNeg: 0.0082, Purity: 0.2256
New best model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9918.purity0.2256.20190809.150916.18.best.pth
scor 3377908 stru 216973.0 sfls 3875453 stp 215268 stn 3162640 sfp 712813 sfn 1705 stot 4092426
Epoch: 19, Training Loss: 0.000003808675300
               Validation Loss: 0.000003900632237, Eff.: 0.9921, FalsePos: 0.1839, FalseNeg: 0.0079, Purity: 0.2319
New best model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9921.purity0.2319.20190809.150916.19.best.pth
scor 3431991 stru 216973.0 sfls 3875453 stp 215338 stn 3216653 sfp 658800 sfn 1635 stot 4092426
Epoch: 20, Training Loss: 0.000003637577499
               Validation Loss: 0.000003700310117, Eff.: 0.9925, FalsePos: 0.1700, FalseNeg: 0.0075, Purity: 0.2463
New best model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9925.purity0.2463.20190809.150916.20.best.pth
scor 3609774 stru 216973.0 sfls 3875453 stp 215210 stn 3394564 sfp 480889 sfn 1763 stot 4092426
Epoch: 21, Training Loss: 0.000003425045107
               Validation Loss: 0.000003451778639, Eff.: 0.9919, FalsePos: 0.1241, FalseNeg: 0.0081, Purity: 0.3092
New best model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9919.purity0.3092.20190809.150916.21.best.pth
scor 3562444 stru 216973.0 sfls 3875453 stp 215176 stn 3347268 sfp 528185 sfn 1797 stot 4092426
Epoch: 22, Training Loss: 0.000003203255718
               Validation Loss: 0.000003794452823, Eff.: 0.9917, FalsePos: 0.1363, FalseNeg: 0.0083, Purity: 0.2895
scor 3656986 stru 216973.0 sfls 3875453 stp 215153 stn 3441833 sfp 433620 sfn 1820 stot 4092426
Epoch: 23, Training Loss: 0.000003039237938
               Validation Loss: 0.000003492669066, Eff.: 0.9916, FalsePos: 0.1119, FalseNeg: 0.0084, Purity: 0.3316
scor 3690051 stru 216973.0 sfls 3875453 stp 214554 stn 3475497 sfp 399956 sfn 2419 stot 4092426
Epoch: 24, Training Loss: 0.000002805763752
               Validation Loss: 0.000004820948106, Eff.: 0.9889, FalsePos: 0.1032, FalseNeg: 0.0111, Purity: 0.3491
scor 3488903 stru 216973.0 sfls 3875453 stp 215724 stn 3273179 sfp 602274 sfn 1249 stot 4092426
Epoch: 25, Training Loss: 0.000002635436165
               Validation Loss: 0.000003025152182, Eff.: 0.9942, FalsePos: 0.1554, FalseNeg: 0.0058, Purity: 0.2637
New best model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9942.purity0.2637.20190809.150916.25.best.pth
scor 3700306 stru 216973.0 sfls 3875453 stp 215589 stn 3484717 sfp 390736 sfn 1384 stot 4092426
Epoch: 26, Training Loss: 0.000002596503538
               Validation Loss: 0.000002516950417, Eff.: 0.9936, FalsePos: 0.1008, FalseNeg: 0.0064, Purity: 0.3556
New best model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9936.purity0.3556.20190809.150916.26.best.pth
scor 3750553 stru 216973.0 sfls 3875453 stp 215229 stn 3535324 sfp 340129 sfn 1744 stot 4092426
Epoch: 27, Training Loss: 0.000002511572754
               Validation Loss: 0.000003208733233, Eff.: 0.9920, FalsePos: 0.0878, FalseNeg: 0.0080, Purity: 0.3876
scor 3658965 stru 216973.0 sfls 3875453 stp 215019 stn 3443945 sfp 431507 sfn 1954 stot 4092426
Epoch: 28, Training Loss: 0.000003782915802
               Validation Loss: 0.000003328214461, Eff.: 0.9910, FalsePos: 0.1113, FalseNeg: 0.0090, Purity: 0.3326
scor 3003059 stru 216973.0 sfls 3875453 stp 215383 stn 2787676 sfp 1087777 sfn 1590 stot 4092426
Epoch: 29, Training Loss: 0.000007041566576
               Validation Loss: 0.000005750184300, Eff.: 0.9927, FalsePos: 0.2807, FalseNeg: 0.0073, Purity: 0.1653
scor 3299895 stru 216973.0 sfls 3875453 stp 214450 stn 3085445 sfp 790008 sfn 2523 stot 4092426
Epoch: 30, Training Loss: 0.000008095668087
               Validation Loss: 0.000005275217518, Eff.: 0.9884, FalsePos: 0.2038, FalseNeg: 0.0116, Purity: 0.2135
scor 3403022 stru 216973.0 sfls 3875453 stp 214492 stn 3188529 sfp 686923 sfn 2481 stot 4092426
Epoch: 31, Training Loss: 0.000007520095779
               Validation Loss: 0.000004135709787, Eff.: 0.9886, FalsePos: 0.1772, FalseNeg: 0.0114, Purity: 0.2380
scor 3449020 stru 216973.0 sfls 3875453 stp 215280 stn 3233740 sfp 641713 sfn 1693 stot 4092426
Epoch: 32, Training Loss: 0.000004614600139
               Validation Loss: 0.000003828812169, Eff.: 0.9922, FalsePos: 0.1656, FalseNeg: 0.0078, Purity: 0.2512
scor 3485184 stru 216973.0 sfls 3875453 stp 215400 stn 3269784 sfp 605669 sfn 1573 stot 4092426
Epoch: 33, Training Loss: 0.000003901346327
               Validation Loss: 0.000003544770607, Eff.: 0.9928, FalsePos: 0.1563, FalseNeg: 0.0072, Purity: 0.2623
scor 3523891 stru 216973.0 sfls 3875453 stp 215346 stn 3308545 sfp 566908 sfn 1627 stot 4092426
Epoch: 34, Training Loss: 0.000003609952015
               Validation Loss: 0.000003530383083, Eff.: 0.9925, FalsePos: 0.1463, FalseNeg: 0.0075, Purity: 0.2753
scor 3545069 stru 216973.0 sfls 3875453 stp 215341 stn 3329728 sfp 545725 sfn 1632 stot 4092426
Epoch: 35, Training Loss: 0.000003399761486
               Validation Loss: 0.000003369509386, Eff.: 0.9925, FalsePos: 0.1408, FalseNeg: 0.0075, Purity: 0.2829
scor 3552616 stru 216973.0 sfls 3875453 stp 215425 stn 3337191 sfp 538262 sfn 1548 stot 4092426
Epoch: 36, Training Loss: 0.000003291538240
               Validation Loss: 0.000003275195013, Eff.: 0.9929, FalsePos: 0.1389, FalseNeg: 0.0071, Purity: 0.2858
scor 3580217 stru 216973.0 sfls 3875453 stp 215397 stn 3364820 sfp 510633 sfn 1576 stot 4092426
Epoch: 37, Training Loss: 0.000003189604129
               Validation Loss: 0.000003271462447, Eff.: 0.9927, FalsePos: 0.1318, FalseNeg: 0.0073, Purity: 0.2967
scor 3629623 stru 216973.0 sfls 3875453 stp 215403 stn 3414220 sfp 461233 sfn 1570 stot 4092426
Epoch: 38, Training Loss: 0.000003123215719
               Validation Loss: 0.000003056568858, Eff.: 0.9928, FalsePos: 0.1190, FalseNeg: 0.0072, Purity: 0.3183
scor 3629291 stru 216973.0 sfls 3875453 stp 215472 stn 3413819 sfp 461634 sfn 1501 stot 4092426
Epoch: 39, Training Loss: 0.000002986671036
               Validation Loss: 0.000002946527047, Eff.: 0.9931, FalsePos: 0.1191, FalseNeg: 0.0069, Purity: 0.3182
Final model saved to: /home/scratch/sitonga/hgcal_ldrd/notebooks/PointnetPreprocessing/PointNet_1766657_71efe6edda_sitonga.eff0.9931.purity0.3182.20190809.150916.final.pth
